{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "44d9d95f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "44d9d95f",
        "outputId": "c30c769b-bda9-40cc-94b9-d26979e6634a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nLog:\\n5/24: Created file and started the SNN construction. Added in data loading and training to test out with MNIST\\ndatabase but there were errors in setting up the training.\\n5/26: After consulting some sample code from a friend, fixed the training code and data loaders. Tested it and it\\nworks, just not very well. Current train accuracy is 10.5% and test accuracy is 11.37%. Will need to adjust parameters.\\n5/31: Changed up the SNN model and made some big changes to how the MNIST data is made. Currently unable to set up the \\nDataLoader, which I will do later. Once that is working, training can be done. \\n6/1: Copied from jupyter notebook to google collab, and ran the code and got the data to be made. Now the model has a \\nproblem in the Convolutional filters. Need to fix\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Author: Arjun Viswanathan\n",
        "# Date Created: 5/26/22\n",
        "# Creating a Siamese Neural Network (SNN) architecture using PyTorch. The jupyter notebook version.\n",
        "# Network takes in 2 sets of inputs, and trains on them to give 2 sets of outputs.\n",
        "# These outputs are then used to compute a distance, and this is passed into a Dense layer to give the output of the SNN\n",
        "\n",
        "'''\n",
        "Log:\n",
        "5/24: Created file and started the SNN construction. Added in data loading and training to test out with MNIST\n",
        "database but there were errors in setting up the training.\n",
        "5/26: After consulting some sample code from a friend, fixed the training code and data loaders. Tested it and it\n",
        "works, just not very well. Current train accuracy is 10.5% and test accuracy is 11.37%. Will need to adjust parameters.\n",
        "5/31: Changed up the SNN model and made some big changes to how the MNIST data is made. Currently unable to set up the \n",
        "DataLoader, which I will do later. Once that is working, training can be done. \n",
        "6/1: Copied from jupyter notebook to google collab, and ran the code and got the data to be made. Now the model has a \n",
        "problem in the Convolutional filters. Need to fix\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch"
      ],
      "metadata": {
        "id": "ZdkIs-Izot2G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c864b7af-51eb-43f2-976d-ce72157e8012"
      },
      "id": "ZdkIs-Izot2G",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sklearn"
      ],
      "metadata": {
        "id": "Fh5yK9d1rk14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "692725be-30e4-4260-bebf-215d5de42ff7"
      },
      "id": "Fh5yK9d1rk14",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.21.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8ae6463a",
      "metadata": {
        "id": "8ae6463a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.nn import Module, Conv2d, MaxPool2d, Linear\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets as dts\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "737aa713",
      "metadata": {
        "id": "737aa713"
      },
      "outputs": [],
      "source": [
        "class CreateSiameseDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
        "        # download the MNIST database into a training and validation set, converting to a Tensor as we download\n",
        "        self.dataset = dts.MNIST(\n",
        "            root= './data',\n",
        "            train= True,\n",
        "            download= True,\n",
        "            transform= self.transform\n",
        "        )\n",
        "        \n",
        "        # Get the images and the labels from imported dataset. May change depending on how the dataset is imported in\n",
        "        self.images = self.dataset.data\n",
        "        self.targets = self.dataset.targets\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        coinflip = random.randint(0, 1) # 0: same image, 1: different image\n",
        "        set1choice = random.randint(0, len(self.targets))\n",
        "        if coinflip:\n",
        "            while(True): # keep looping until we find the image we want that either matches or differentiates the original image\n",
        "                set2choice = random.randint(0, len(self.targets))\n",
        "                if(self.targets[set1choice] != self.targets[set2choice] and set1choice != set2choice):\n",
        "                    img1 = self.images[set1choice]\n",
        "                    img2 = self.images[set2choice]\n",
        "                    label = torch.tensor(1)\n",
        "                    break # load them and break for next coin flip\n",
        "        else:\n",
        "            while(True):\n",
        "                set2choice = random.randint(0, len(self.targets))\n",
        "                if(self.targets[set1choice] == self.targets[set2choice] and set1choice != set2choice):\n",
        "                    img1 = self.images[set1choice]\n",
        "                    img2 = self.images[set2choice]\n",
        "                    label = torch.tensor(0)\n",
        "                    break\n",
        "        return img1, img2, label\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e0a47ed5",
      "metadata": {
        "id": "e0a47ed5"
      },
      "outputs": [],
      "source": [
        "siamesedata = CreateSiameseDataset()\n",
        "batchsize = 64\n",
        "siamesedataloader = DataLoader(siamesedata, shuffle=True, num_workers=2, batch_size=batchsize)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the data and see what was created in the DataLoader\n",
        "img1, img2, l = next(iter(siamesedataloader))\n",
        "for i in range(1):\n",
        "    plt.figure(i)\n",
        "    plt.imshow(img1[i], cmap='gray')\n",
        "    plt.figure(i+1)\n",
        "    plt.imshow(img2[i], cmap='gray')\n",
        "    print(\"Label: \", l[i])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "o92NbOOpu6TR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "9f004a41-528c-4818-fbff-32a8b43262b3"
      },
      "id": "o92NbOOpu6TR",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label:  tensor(1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAMuUlEQVR4nO3db6hc9Z3H8c8n2SagCZKsGC5pdvuHPLAoJhJCoWVNKS1WIrGImjyoWSh7fVBrC1U2WLSCCHXpn+yjwA1qU2nTFFrrRctu01DQPkjxKnc1RpqkNdqEa+5WwaYKZk2+++Aey22cc2Yy58yc8X7fL7jMzPnOOefLiR/Pv5n5OSIEYOFb1HYDAIaDsANJEHYgCcIOJEHYgST+YZgrs82lf2DAIsKdptfas9u+1vbvbR+zvaPOsgAMlvu9z257saQjkj4n6YSkZyRti4jDFfOwZwcGbBB79o2SjkXEHyPijKSfSNpSY3kABqhO2FdL+tO81yeKaX/H9rjtKdtTNdYFoKaBX6CLiAlJExKH8UCb6uzZT0paM+/1h4tpAEZQnbA/I2mt7Y/aXiJpq6TJZtoC0LS+D+Mj4l3bt0v6b0mLJT0cES821hmARvV9662vlXHODgzcQD5UA+CDg7ADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQRN/js0uS7eOSTks6K+ndiNjQRFMAmlcr7IXPRMSfG1gOgAHiMB5Iom7YQ9KvbD9re7zTG2yP256yPVVzXQBqcET0P7O9OiJO2r5M0n5JX42Ipyre3//KAPQkItxpeq09e0ScLB5nJT0maWOd5QEYnL7Dbvti28vfey7p85IONdUYgGbVuRq/StJjtt9bzo8j4r8a6QpA42qds1/wyjhnBwZuIOfsAD44CDuQBGEHkiDsQBKEHUiiiS/CoItrrrmmsn711VcPqZPRcskll1TW77nnnsr6okXV+6p9+/aV1rZu3Vo570LEnh1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkuBbbw3YtWtXZX3btm2V9eXLl1fWh/lvdL7iK8ylRrm3K6+8srR2+PDhptsZGXzrDUiOsANJEHYgCcIOJEHYgSQIO5AEYQeS4PvsPbriiitKazfeeGPlvMuWLWu6HfTgzTffbLuFkcKeHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeS4D57j5YuXVpae+uttyrn7Vbv9vvn586dq6zXMTk5WVl/+umnay1/7dq1pbX777+/1rJPnz5dWT979myt5S80Xffsth+2PWv70LxpK23vt320eFwx2DYB1NXLYfwPJF173rQdkg5ExFpJB4rXAEZY17BHxFOS3jhv8hZJe4rneyTd0HBfABrW7zn7qoiYKZ6/JmlV2Rttj0sa73M9ABpS+wJdRETVD0lGxISkCWnh/uAk8EHQ7623U7bHJKl4nG2uJQCD0G/YJyVtL55vl/R4M+0AGJSuvxtve6+kTZIulXRK0rck/ULSTyX9k6RXJN0cEedfxOu0LA7jkxkbGyutPfHEE5XzXnXVVZX1nTt3VtbvvPPOyvpCVfa78V3P2SOibISDz9bqCMBQ8XFZIAnCDiRB2IEkCDuQBGEHkmDIZgzUjh3l35F64IEHai178eLFteZfqBiyGUiOsANJEHYgCcIOJEHYgSQIO5AEYQeS4KekUcvmzZsr6/fee29prdtnPKanp/vqCZ2xZweSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJLjPjlouv/zyyvqSJUtKa7Oz1WOLXH/99X31hM7YswNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEtxnR6Xly5dX1u+4446+l7179+7K+szMTN/Lxvt13bPbftj2rO1D86bdZ/uk7eni77rBtgmgrl4O438g6doO078fEeuKv1822xaApnUNe0Q8JemNIfQCYIDqXKC73fbzxWH+irI32R63PWV7qsa6ANTUb9h3Sfq4pHWSZiR9t+yNETERERsiYkOf6wLQgL7CHhGnIuJsRJyTtFvSxmbbAtC0vsJue2zeyy9KOlT2XgCjoet9dtt7JW2SdKntE5K+JWmT7XWSQtJxSbcNsEe0aHJysrI+NjZWWT9+/Hhp7dFHH+2nJfSpa9gjYluHyQ8NoBcAA8THZYEkCDuQBGEHkiDsQBKEHUiCr7ii0qZNmyrr586dq6zv27evtHbs2LF+WkKf2LMDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBLcZ09u3bp1lfVu99FfffXVyvojjzxywT1hMNizA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAS3Gdf4JYuXVpZv+uuu2ot/+DBg5V1vrM+OtizA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAS3Gdf4C677LLK+i233FJr+RdddFFlveo+/zvvvFNr3bgwXffsttfY/o3tw7ZftP21YvpK2/ttHy0eVwy+XQD96uUw/l1J34iIT0j6pKSv2P6EpB2SDkTEWkkHitcARlTXsEfETEQ8Vzw/LeklSaslbZG0p3jbHkk3DKpJAPVd0Dm77Y9IWi/pd5JWRcRMUXpN0qqSecYljfffIoAm9Hw13vYyST+T9PWI+Mv8WkSEpOg0X0RMRMSGiNhQq1MAtfQUdtsf0lzQfxQRPy8mn7I9VtTHJM0OpkUATeh6GG/bkh6S9FJEfG9eaVLSdknfLh4fH0iHGGmrV6+urK9cubK0NjMzU1pD83o5Z/+UpC9JesH2dDHtbs2F/Ke2vyzpFUk3D6ZFAE3oGvaI+K0kl5Q/22w7AAaFj8sCSRB2IAnCDiRB2IEkCDuQBF9xTW7uYxTlFi2q3h+sX7++sn7rrbeW1h588MHKedEs9uxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kITnfmRmSCuzh7cySJLWrFlTWX/55Zcr693uw3f77+fMmTOltZtuuqly3ieffLKyjs4iouM/Gnt2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiC77NjoI4cOVJaO3jw4BA7AXt2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiil/HZ10j6oaRVkkLSRET8p+37JP2bpP8t3np3RPxyUI2iP6+//nplvdt3xjdv3lxZf/vttyvrO3fuLK116w3N6uVDNe9K+kZEPGd7uaRnbe8vat+PiO8Mrj0ATellfPYZSTPF89O2X5K0etCNAWjWBZ2z2/6IpPWSfldMut3287Yftr2iZJ5x21O2p2p1CqCWnsNue5mkn0n6ekT8RdIuSR+XtE5ze/7vdpovIiYiYkNEbGigXwB96instj+kuaD/KCJ+LkkRcSoizkbEOUm7JW0cXJsA6uoads/9vOhDkl6KiO/Nmz42721flHSo+fYANKWXq/GfkvQlSS/Yni6m3S1pm+11mrsdd1zSbQPpELV0uzV29OjRWsu/7bbqf/a9e/fWWj6a08vV+N9K6vQ71NxTBz5A+AQdkARhB5Ig7EAShB1IgrADSRB2IAmGbAYWGIZsBpIj7EAShB1IgrADSRB2IAnCDiRB2IEkhj1k858lvTLv9aXFtFE0qr2Nal8SvfWryd7+uaww1A/VvG/l9tSo/jbdqPY2qn1J9NavYfXGYTyQBGEHkmg77BMtr7/KqPY2qn1J9NavofTW6jk7gOFpe88OYEgIO5BEK2G3fa3t39s+ZntHGz2UsX3c9gu2p9sen64YQ2/W9qF501ba3m/7aPHYcYy9lnq7z/bJYttN276upd7W2P6N7cO2X7T9tWJ6q9uuoq+hbLehn7PbXizpiKTPSToh6RlJ2yLi8FAbKWH7uKQNEdH6BzBs/4ukv0r6YURcUUz7D0lvRMS3i/9RroiIfx+R3u6T9Ne2h/EuRisamz/MuKQbJP2rWtx2FX3drCFstzb27BslHYuIP0bEGUk/kbSlhT5GXkQ8JemN8yZvkbSneL5Hc/+xDF1JbyMhImYi4rni+WlJ7w0z3uq2q+hrKNoI+2pJf5r3+oRGa7z3kPQr28/aHm+7mQ5WRcRM8fw1SavabKaDrsN4D9N5w4yPzLbrZ/jzurhA936fjoirJX1B0leKw9WRFHPnYKN077SnYbyHpcMw43/T5rbrd/jzutoI+0lJa+a9/nAxbSRExMnicVbSYxq9oahPvTeCbvE423I/fzNKw3h3GmZcI7Dt2hz+vI2wPyNpre2P2l4iaaukyRb6eB/bFxcXTmT7Ykmf1+gNRT0paXvxfLukx1vs5e+MyjDeZcOMq+Vt1/rw5xEx9D9J12nuivwfJH2zjR5K+vqYpP8p/l5suzdJezV3WPd/mru28WVJ/yjpgKSjkn4taeUI9faopBckPa+5YI211NunNXeI/ryk6eLvura3XUVfQ9lufFwWSIILdEAShB1IgrADSRB2IAnCDiRB2IEkCDuQxP8DP+zyRzEAFfcAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data logistics. We want it to be approx 50% of 1s and 0s to have good training\n",
        "print(\"All labels: \", l)\n",
        "print(\"Number of 1s: \", np.count_nonzero(l.numpy()==1))\n",
        "print(\"Number of 0s: \", np.count_nonzero(l.numpy()==0))"
      ],
      "metadata": {
        "id": "Wl3FogTNvYY9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05a7d8e8-e961-4378-aa6a-1d52cc3c4758"
      },
      "id": "Wl3FogTNvYY9",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All labels:  tensor([1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1,\n",
            "        1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
            "        1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0])\n",
            "Number of 1s:  32\n",
            "Number of 0s:  32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "f7caef08",
      "metadata": {
        "id": "f7caef08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d40e6f6c-0e9f-489d-9d31-1d0fdd880b49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Set Image Dimensions:  torch.Size([64, 28, 28])\n",
            "Set Single Image Dimension:  torch.Size([28, 28])\n",
            "Set Label Dimensions:  torch.Size([64])\n"
          ]
        }
      ],
      "source": [
        "# view the dimensions and num classes of the input images\n",
        "for (img1, img2, l) in siamesedataloader:\n",
        "    print(\"Set Image Dimensions: \", img1.shape)\n",
        "    print(\"Set Single Image Dimension: \", img1[0].shape)\n",
        "    print(\"Set Label Dimensions: \", l.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f7b330c0",
      "metadata": {
        "id": "f7b330c0"
      },
      "outputs": [],
      "source": [
        "# SNN class with model\n",
        "class SiameseNeuralNetwork(Module):\n",
        "    def __init__(self):\n",
        "        super(SiameseNeuralNetwork, self).__init__()\n",
        "        # First L-2 layers have convolutions followed by max pooling and activation ReLU\n",
        "        # The L-1 layer is a Dense layer which will give a feature vector with activation Sigmoid\n",
        "        # The L layer (output layer) will then compute the classification\n",
        "        self.conv1 = Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding='same')\n",
        "        self.pool1 = MaxPool2d(kernel_size=2, stride=2, padding=1)\n",
        "\n",
        "        self.conv2 = Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding='same')\n",
        "        self.pool2 = MaxPool2d(kernel_size=2, stride=2, padding=1)\n",
        "\n",
        "        self.conv3 = Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding='same')\n",
        "        self.pool3 = MaxPool2d(kernel_size=2, stride=2, padding=1)\n",
        "\n",
        "        self.conv4 = Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding='same')\n",
        "\n",
        "        self.fc1 = Linear(in_features=256, out_features=1024)\n",
        "        self.fc2 = Linear(in_features=1024, out_features=1)\n",
        "\n",
        "    def forward_on_input(self, x):\n",
        "        x = self.pool1(F.relu(self.conv1(x)))\n",
        "        x = self.pool2(F.relu(self.conv2(x)))\n",
        "        x = self.pool3(F.relu(self.conv3(x)))\n",
        "        x = F.relu(self.conv4(x))\n",
        "\n",
        "        x = x.flatten(start_dim=1)\n",
        "\n",
        "        x = torch.sigmoid(self.fc1(x))\n",
        "        return x\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        y1 = self.forward_on_input(x1)\n",
        "        y2 = self.forward_on_input(x2)\n",
        "        d = torch.abs(y1 - y2)\n",
        "        p = self.fc2(d)\n",
        "        return p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "4cfb3e86",
      "metadata": {
        "id": "4cfb3e86"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "model = SiameseNeuralNetwork()\n",
        "\n",
        "# If a GPU is available, then send it to that GPU rather than train on CPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "num_epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "724168f1",
      "metadata": {
        "id": "724168f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4db6134-9442-40d7-ed45-9dd42f2169dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "0df92422",
      "metadata": {
        "id": "0df92422",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "160483fd-2c1b-4603-8a1b-09de7f275940"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SiameseNeuralNetwork(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# show model summary\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "432a8a02",
      "metadata": {
        "id": "432a8a02"
      },
      "outputs": [],
      "source": [
        "# set the loss, optimizer, and model device\n",
        "opt = torch.optim.Adam(model.parameters(), lr=0.005)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "18842570",
      "metadata": {
        "id": "18842570"
      },
      "outputs": [],
      "source": [
        "# Compute the accuracy of the model at each epoch\n",
        "def accuracy(output, target, batch_size):\n",
        "    corrects = (torch.max(output, 1)[1].view(target.size()).data == target.data).sum()\n",
        "    accuracy = 100.0 * corrects / batch_size\n",
        "    return accuracy.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37924ca0",
      "metadata": {
        "id": "37924ca0"
      },
      "outputs": [],
      "source": [
        "# training\n",
        "for epoch in range(num_epochs):\n",
        "    train_running_loss = 0.0\n",
        "    train_accuracy = 0.0\n",
        "    model = model.train()\n",
        "\n",
        "    # training step: iterate through the batch and get the images and labels at each x\n",
        "    for x, (x1, x2, l) in enumerate(siamesedataloader):        \n",
        "        # sending images and labels to device (GPU or CPU)\n",
        "        x1 = x1.to(device)\n",
        "        x2 = x2.to(device)\n",
        "        l = l.to(device)\n",
        "\n",
        "        # pass 2 sets of inputs into the snn and gives p, the output\n",
        "        output = model(x1, x2)\n",
        "        loss = l*math.log(output) + (1-l)*math.log(1-output)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        train_running_loss += loss.detach().item()\n",
        "        train_accuracy += accuracy(output, labels, batchsize)\n",
        "\n",
        "    model.eval()\n",
        "    print('Epoch %d | Loss: %.4f | Train Accuracy: %.2f'%(epoch+1, train_running_loss / x, train_accuracy / x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6206c6cf",
      "metadata": {
        "id": "6206c6cf"
      },
      "outputs": [],
      "source": [
        "test_accuracy = 0.0\n",
        "for y, (y1, y2, l) in enumerate(siamesedataloader):\n",
        "    y1 = y1.to(device)\n",
        "    y2 = y2.to(device)\n",
        "    l = l.to(device)\n",
        "\n",
        "    outputs = model(y1, y2)\n",
        "    test_accuracy += accuracy(outputs, l, batchsize)\n",
        "print('Test Accuracy: %.2f'%(test_accuracy / y))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "name": "snn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}