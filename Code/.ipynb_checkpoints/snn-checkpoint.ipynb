{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d9d95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Arjun Viswanathan\n",
    "# Date Created: 5/26/22\n",
    "# Creating a Siamese Neural Network (SNN) architecture using PyTorch. The jupyter notebook version.\n",
    "# Network takes in 2 sets of inputs, and trains on them to give 2 sets of outputs.\n",
    "# These outputs are then used to compute a distance, and this is passed into a Dense layer to give the output of the SNN\n",
    "\n",
    "'''\n",
    "Log:\n",
    "5/24: Created file and started the SNN construction. Added in data loading and training to test out with MNIST\n",
    "database but there were errors in setting up the training.\n",
    "5/26: After consulting some sample code from a friend, fixed the training code and data loaders. Tested it and it\n",
    "works, just not very well. Current train accuracy is 10.5% and test accuracy is 11.37%. Will need to adjust parameters.\n",
    "5/31: Changed up the SNN model and made some big changes to how the MNIST data is made. Currently unable to set up the \n",
    "DataLoader, which I will do later. Once that is working, training can be done. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae6463a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import math\n",
    "from torch.nn import Module, Conv2d, MaxPool2d, Linear\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets as dts\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737aa713",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateSiameseDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "        # download the MNIST database into a training and validation set, converting to a Tensor as we download\n",
    "        self.dataset = dts.MNIST(\n",
    "            root= './data',\n",
    "            train= True,\n",
    "            download= True,\n",
    "            transform= self.transform\n",
    "        )\n",
    "        \n",
    "        # Get the images and the labels from imported dataset. May change depending on how the dataset is imported in\n",
    "        self.images = self.dataset.data\n",
    "        self.targets = self.dataset.targets\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        coinflip = random.randint(0, 1) # 0: same image, 1: different image\n",
    "        set1randlabel = random.choice(self.targets)\n",
    "        if coinflip:\n",
    "            while(True): # keep looping until we find the image we want that either matches or differentiates the original image\n",
    "                set2randlabel = random.choice(self.targets)\n",
    "                if(self.targets[set1randlabel] != self.targets[set2randlabel] and set1randlabel != set2randlabel):\n",
    "                    img1 = self.images[set1randlabel]\n",
    "                    img2 = self.images[set2randlabel]\n",
    "                    label = torch.tensor(1)\n",
    "                    break # load them into dict and break for next coin flip\n",
    "        else:\n",
    "            while(True):\n",
    "                set2randlabel = random.choice(self.targets)\n",
    "                if(self.targets[set1randlabel] == self.targets[set2randlabel] and set1randlabel != set2randlabel):\n",
    "                    img1 = self.images[set1randlabel]\n",
    "                    img2 = self.images[set2randlabel]\n",
    "                    label = torch.tensor(0)\n",
    "                    break\n",
    "        return img1, img2, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a47ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamesedata = CreateSiameseDataset()\n",
    "batchsize = 64\n",
    "siamesedataloader = DataLoader(siamesedata, shuffle=True, num_workers=2, batch_size=batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7caef08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the dimensions and num classes of the input images\n",
    "for img1, img2, l in siamesedataloader:\n",
    "    print(\"Set Image Dimensions: \", img1.shape)\n",
    "    print(\"Set Single Image Dimension: \", img1[0].shape)\n",
    "    print(\"Set Label Dimensions: \", l.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b330c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNN class with model\n",
    "class SiameseNeuralNetwork(Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNeuralNetwork, self).__init__()\n",
    "        # First L-2 layers have convolutions followed by max pooling and activation ReLU\n",
    "        # The L-1 layer is a Dense layer which will give a feature vector with activation Sigmoid\n",
    "        # The L layer (output layer) will then compute the classification\n",
    "        self.conv1 = Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding='same')\n",
    "        self.pool1 = MaxPool2d(kernel_size=2, stride=2, padding=1)\n",
    "\n",
    "        self.conv2 = Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding='same')\n",
    "        self.pool2 = MaxPool2d(kernel_size=2, stride=2, padding=1)\n",
    "\n",
    "        self.conv3 = Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding='same')\n",
    "        self.pool3 = MaxPool2d(kernel_size=2, stride=2, padding=1)\n",
    "\n",
    "        self.conv4 = Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding='same')\n",
    "\n",
    "        self.fc1 = Linear(in_features=256, out_features=1024)\n",
    "        self.fc2 = Linear(in_features=1024, out_features=1)\n",
    "\n",
    "    def forward_on_input(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = self.pool3(F.relu(self.conv3(x)))\n",
    "        x = F.relu(self.conv4(x))\n",
    "\n",
    "        x = x.flatten(start_dim=1)\n",
    "\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        y1 = self.forward_on_input(x1)\n",
    "        y2 = self.forward_on_input(x2)\n",
    "        d = torch.abs(y1 - y2)\n",
    "        p = self.fc2(d)\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfb3e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model = SiameseNeuralNetwork()\n",
    "\n",
    "# If a GPU is available, then send it to that GPU rather than train on CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724168f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df92422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show model summary\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432a8a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the loss, optimizer, and model device\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18842570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the accuracy of the model at each epoch\n",
    "def accuracy(output, target, batch_size):\n",
    "    corrects = (torch.max(output, 1)[1].view(target.size()).data == target.data).sum()\n",
    "    accuracy = 100.0 * corrects / batch_size\n",
    "    return accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37924ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "for epoch in range(num_epochs):\n",
    "    train_running_loss = 0.0\n",
    "    train_accuracy = 0.0\n",
    "    model = model.train()\n",
    "\n",
    "    # training step: iterate through the batch and get the images and labels at each x\n",
    "    for x, (x1, x2, l) in enumerate(siamesedataloader):        \n",
    "        # sending images and labels to device (GPU or CPU)\n",
    "        x1 = x1.to(device)\n",
    "        x2 = x2.to(device)\n",
    "        l = l.to(device)\n",
    "\n",
    "        # pass 2 sets of inputs into the snn and gives p, the output\n",
    "        output = model(x1, x2)\n",
    "        loss = l*math.log(output) + (1-l)*math.log(1-output)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        train_running_loss += loss.detach().item()\n",
    "        train_accuracy += accuracy(output, labels, batchsize)\n",
    "\n",
    "    model.eval()\n",
    "    print('Epoch %d | Loss: %.4f | Train Accuracy: %.2f'%(epoch+1, train_running_loss / x, train_accuracy / x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6206c6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = 0.0\n",
    "for y, (y1, y2, l) in enumerate(siamesedataloader):\n",
    "    y1 = y1.to(device)\n",
    "    y2 = y2.to(device)\n",
    "    l = l.to(device)\n",
    "\n",
    "    outputs = model(y1, y2)\n",
    "    test_accuracy += accuracy(outputs, l, batchsize)\n",
    "print('Test Accuracy: %.2f'%(test_accuracy / y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
